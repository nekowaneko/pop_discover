{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8671cd2-37e4-4acc-bc20-9a6b4420b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#work_ID = 121188719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38defef-e43a-4c2f-8607-fe19909046fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search from ID: 121188700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding valid work IDs: 100%|█| 50/50 [03:05<00:00,  3.72s/ID, Latest ID: 121188"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached maximum attempts. Found 50 valid work IDs.\n",
      "Valid work IDs: [121188700, 121188701, 121188702, 121188703, 121188704, 121188706, 121188707, 121188708, 121188709, 121188710, 121188711, 121188712, 121188713, 121188714, 121188716, 121188718, 121188719, 121188721, 121188722, 121188723, 121188724, 121188725, 121188726, 121188727, 121188728, 121188729, 121188730, 121188731, 121188732, 121188733, 121188734, 121188736, 121188738, 121188739, 121188740, 121188741, 121188742, 121188743, 121188744, 121188745, 121188747, 121188748, 121188749, 121188751, 121188752, 121188753, 121188754, 121188755, 121188756, 121188758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def check_pixiv_work_ids(start_id, max_attempts=1000):\n",
    "    valid_ids = []\n",
    "    \n",
    "    # 創建tqdm進度條\n",
    "    with tqdm(total=50, desc=\"Finding valid work IDs\", unit=\"ID\") as pbar:\n",
    "        for attempt in range(max_attempts):\n",
    "            work_id = start_id + attempt\n",
    "            url = f\"https://www.pixiv.net/artworks/{work_id}\"\n",
    "            \n",
    "            try:\n",
    "                response = requests.head(url)\n",
    "                if response.status_code == 200:\n",
    "                    valid_ids.append(work_id)\n",
    "                    pbar.update(1)  # 更新進度條\n",
    "                    pbar.set_postfix_str(f\"Latest ID: {work_id}\")  # 顯示最新找到的ID\n",
    "                \n",
    "                if len(valid_ids) == 50:\n",
    "                    break\n",
    "                \n",
    "                # 添加延遲以避免過於頻繁的請求\n",
    "                time.sleep(3)\n",
    "            \n",
    "            except requests.RequestException as e:\n",
    "                tqdm.write(f\"Error checking work ID {work_id}: {e}\")\n",
    "    \n",
    "    if len(valid_ids) == 50:\n",
    "        print(\"\\nSuccessfully found 10 valid work IDs.\")\n",
    "    else:\n",
    "        print(f\"\\nReached maximum attempts. Found {len(valid_ids)} valid work IDs.\")\n",
    "    \n",
    "    return valid_ids\n",
    "\n",
    "# 使用函數\n",
    "start_id = 121188700  # 隨機選擇起始ID\n",
    "print(f\"Starting search from ID: {start_id}\")\n",
    "result = check_pixiv_work_ids(start_id)\n",
    "print(\"Valid work IDs:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93a673e5-8c78-46cf-878e-b0312b5eb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def save_webpage_as_single_file(url, filename):\n",
    "    try:\n",
    "        # 发送 GET 请求获取网页内容\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # 检查请求是否成功\n",
    "        time.sleep(np.random.randint(3,7))\n",
    "\n",
    "        # 解析网页内容\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 获取网页的标题\n",
    "        title = soup.title.string if soup.title else 'webpage'\n",
    "        \n",
    "        # 创建 .mhtml 文件内容\n",
    "        mhtml_content = f\"<!DOCTYPE html>\\n<html>\\n<head>\\n<title>{title}</title>\\n</head>\\n<body>\\n\"\n",
    "        mhtml_content += str(soup)  # 添加网页内容\n",
    "        mhtml_content += \"\\n</body>\\n</html>\"\n",
    "\n",
    "        # 保存为 .mhtml 文件\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(mhtml_content)\n",
    "\n",
    "        print(f\"网页内容已成功保存为 {filename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"请求失败: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存文件时出错: {e}\")\n",
    "\n",
    "# 输入 URL 和文件名\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0078b3f-3262-4e94-857f-53a9e79bac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "# 提取信息的函数\n",
    "def extract_info_from_mhtml(mhtml_file,work_ID):\n",
    "    with open(mhtml_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # 使用 BeautifulSoup 解析 HTML 内容\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # 提取 <title> 标签的内容\n",
    "    title = soup.title.string if soup.title else '无标题'\n",
    "    \n",
    "     # 使用正则表达式提取多个 \"tag\"\n",
    "    tag_pattern = re.findall(r'\"tag\"\\s*:\\s*\"([^\"]+)\"', content)\n",
    "    \n",
    "    # 使用正则表达式提取 \"likeCount\", \"bookmarkCount\", \"viewCount\"\n",
    "    like_count_pattern = re.search(r'\"likeCount\"\\s*:\\s*(\\d+)', content)\n",
    "    bookmark_count_pattern = re.search(r'\"bookmarkCount\"\\s*:\\s*(\\d+)', content)\n",
    "    view_count_pattern = re.search(r'\"viewCount\"\\s*:\\s*(\\d+)', content)\n",
    "    image_pattern = re.search(r'\"regular\"\\s*:\\s*\"([^\"]+)\"', content)\n",
    "\n",
    "    # 获取正则表达式的匹配结果\n",
    "    tags = tag_pattern if tag_pattern else ['无标签']\n",
    "    like_count = like_count_pattern.group(1) if like_count_pattern else '无点赞数'\n",
    "    bookmark_count = bookmark_count_pattern.group(1) if bookmark_count_pattern else '无收藏数'\n",
    "    view_count = view_count_pattern.group(1) if view_count_pattern else '无浏览数'\n",
    "    image_count = image_pattern.group(1) if image_pattern else '無影像連結'\n",
    "    return {\n",
    "        'work_ID': str(work_ID),\n",
    "        'title': title.split(' - ')[0],  # 清理标题内容\n",
    "        'tags': ', '.join(tags),  # 标签列表转为字符串\n",
    "        'like_count': like_count,\n",
    "        'bookmark_count': bookmark_count,\n",
    "        'view_count': view_count,\n",
    "        'image url': image_count\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# 将数据追加到 SQLite 数据库的函数\n",
    "def append_to_sqlite(info, db_filename='web_info.db'):\n",
    "    # 连接 SQLite 数据库（如果文件不存在，会自动创建）\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 创建表格（如果不存在）\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS web_info (\n",
    "            work_ID TEXT PRIMARY KEY,\n",
    "            title TEXT,\n",
    "            tags TEXT,\n",
    "            like_count INTEGER,\n",
    "            bookmark_count INTEGER,\n",
    "            view_count INTEGER,\n",
    "            image_url TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # 插入数据，如果 work_ID 已存在则忽略插入\n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO web_info (work_ID, title, tags, like_count, bookmark_count, view_count, image_url)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        info['work_ID'],\n",
    "        info['title'],\n",
    "        info['tags'],\n",
    "        int(info['like_count']),\n",
    "        int(info['bookmark_count']),\n",
    "        int(info['view_count']),\n",
    "        info['image url']\n",
    "    ))\n",
    "\n",
    "    # 提交更改并关闭连接\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16847b22-1171-48b2-96de-df37fcdbced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网页内容已成功保存为 121188700.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188701.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188702.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188703.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188704.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188706.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188707.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188708.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188709.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188710.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188711.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188712.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188713.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188714.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188716.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188718.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188719.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188721.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188722.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188723.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188724.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188725.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188726.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188727.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188728.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188729.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188730.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188731.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188732.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188733.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188734.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188736.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188738.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188739.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188740.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188741.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188742.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188743.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188744.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188745.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188747.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188748.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188749.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188751.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188752.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188753.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188754.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188755.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188756.mhtml\n",
      "新信息已成功追加到 web_info.db\n",
      "网页内容已成功保存为 121188758.mhtml\n",
      "新信息已成功追加到 web_info.db\n"
     ]
    }
   ],
   "source": [
    "db_filename = 'web_info.db'\n",
    "for work_ID in result:\n",
    "    url = f'https://www.pixiv.net/artworks/{work_ID}'\n",
    "    filename = f'{work_ID}.mhtml'\n",
    "    save_webpage_as_single_file(url, filename)\n",
    "    # 示例：提取和追加数据\n",
    "    mhtml_file = f'{work_ID}.mhtml'  # 替换为实际的 .mhtml 文件路径\n",
    "    info = extract_info_from_mhtml(mhtml_file,work_ID)\n",
    "\n",
    "    # 将提取的信息追加到 'web_info.xlsx'\n",
    "    append_to_sqlite(info)\n",
    "\n",
    "    print(f\"新信息已成功追加到 {db_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cd90b55-71ee-4e77-bd49-7115e3a96b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('121188700', 'VTuber, ファンアート, 美少女, ショートカット, ロック少女, 夏, web, YouTube, YouTuber, VTuber')\n",
      "('121188701', 'R-18, Naruto, Tsunade, 綱手, うずまきナルト, NarutoUzumaki, NARUTO, creampie, bikini')\n",
      "('121188702', 'R-18, pokemon, pikachulibre, pikachu, furry, ポケモン, 盛るペコ')\n",
      "('121188703', 'R-18, マギアレコード, 環いろは')\n",
      "('121188704', '女の子, 綺麗, かわいい, 風景, 獣耳, ファンタジー, 悪魔, 美少女, 悪魔娘, サキュバス')\n",
      "('121188706', 'R-18, 種付けプレス, ビッチ, 痴女, チン負け, わからせ')\n",
      "('121188707', 'R-18, オリジナル, 眼鏡, マスク, ローター, 調教, JK, たくしあげ, ノーブラ, 貧乳')\n",
      "('121188708', 'R-18, Fate/GrandOrder, Fate, FGO, 藤丸立香, ジャンヌ・オルタ, 邪ンヌ, ジャンヌオルタ')\n",
      "('121188709', '人形, 天使, オリジナルイラスト, オリジナル, イラスト')\n",
      "('121188710', 'pokemon, ハクリュー, Dragonair, ポケモン, pokemon')\n",
      "('121188711', 'R-18, 咲-Saki-, 原村和, 敗北, NTR, 肉便器, ビキニ, 爆乳, AIイラスト, NovelAI')\n",
      "('121188712', 'R-18, EpicSeven, epic7, luna, 女の子, 熟女, 魅惑の谷間, 巨乳, AIイラスト, 3D')\n",
      "('121188713', '手描き, 東方, 東方Project, 水着, 純狐, 東方水着娘')\n",
      "('121188714', 'R-18, Texas, テキサス(アークナイツ), 明日方舟, 德克萨斯, 博德, 缄默德克萨斯, 内射, 受精')\n",
      "('121188716', 'ケモノ, メスケモ, furry, anthro, ドワ子, 剣と魔法と学園モノ。, ドワーフ, 脱ぎかけ, スパッツ')\n",
      "('121188718', 'R-18, 五等分の花嫁, 中野三玖, 着衣セックス, 中出し, 腋, ワキ, 腋舐め')\n",
      "('121188719', 'ウマ娘プリティーダービー, ライスシャワー(ウマ娘), ウマ娘, 水着ウマ娘, スク水')\n",
      "('121188721', 'R-18, もんむす・くえすと!, エンジェルグール, 逆レイプ, 搾精, 青肌, モンスター娘, 人外娘, 女性上位, ドMホイホイ')\n",
      "('121188722', 'R-18, Skeb, commission, ラブライブ!虹ヶ咲学園スクールアイドル同好会, 優木せつ菜, 拘束, 鞭')\n",
      "('121188723', '響け!ユーフォニアム, 中川夏紀, 吉川優子, なかよし川, 六角大王')\n",
      "('121188724', '漫画, ヒシミラクル(ウマ娘), ダンツフレーム(ウマ娘), ウマ娘プリティーダービー, ウマ娘, 真面目マッサージ, コミケ, C104')\n",
      "('121188725', '女の子, 創作, イラスト, オリキャラ, 少女, 原创, 美少女')\n",
      "('121188726', 'R-18')\n",
      "('121188727', '9S, 2B, 人類に栄光あれ, ニーアオートマタ, NieRAutomata, ニーア, NieR, NieR:Automata, ニーアドラゴンボール, フュージョン, NieR, NieR:Automata, 9S')\n",
      "('121188728', '東方, ふといの, ぽっちゃり, 肥満化, ミスティア・ローレライ, 東方Project')\n",
      "('121188729', 'R-18, 女の子, 裸体, 鸣潮, WutheringWaves, 釉瑚')\n",
      "('121188730', 'ブルーアーカイブ, 銀鏡イオリ, 尾刃カンナ, 銀鏡イオリ(水着), 尾刃カンナ(水着), 先生(ブルーアーカイブ), 乳合わせ, 胸囲の格差社会, ブルーアーカイブ1000users入り')\n",
      "('121188731', 'ハクオウ, ドラクエ10, DQ10')\n",
      "('121188732', 'slamdunk, 一ノ倉聡, 山王工高, 松本稔, イチ松, 倉松, スラムダンク, fanart, イラスト, slamdunk')\n",
      "('121188733', 'マッ腐ル, 女体化, ワス, 不穏, 暗い, BL')\n",
      "('121188734', 'トウカイテイオー(ウマ娘), ウマ娘プリティーダービー, ウマ娘, トウカイテイオー, UmaMusumePrettyDerby, 우마무스메')\n",
      "('121188736', '女の子, imagithorn, SFM, SourceFilmmaker, Paris2024Olympics, Paris2024, SenranKagura, 女孩子, olympics2024, YusufDikec')\n",
      "('121188738', 'R-18, VRchat, 獣耳')\n",
      "('121188739', 'ホームランダー, THEBOES')\n",
      "('121188740', 'R-18, art, drawing, lewd, nsfw, thicc, whale, mermaid, ass, big_ass')\n",
      "('121188741', '女の子, ダーク, 赤い傘, 目')\n",
      "('121188742', 'スノーボウルプラネット, ドラゴン, ケモノ, オリジナル')\n",
      "('121188743', 'R-18, 女の子, 全裸')\n",
      "('121188744', '어몽어스, amongus')\n",
      "('121188745', 'R-18, 飯P, 飯マジュ, ピッコロ, マジュニア')\n",
      "('121188747', '東方Project, フランドール・スカーレット')\n",
      "('121188748', 'トレジェイ, ツイ腐テ, ツイ腐テ100users入り, BL')\n",
      "('121188749', 'C104, コミックマーケット104, VTuber, バ美肉, 舞柏マイコ, C104')\n",
      "('121188751', '落書き')\n",
      "('121188752', 'ロリ, ゆるゆり, キョウゲ族, キョウゲわん, キョウゲにゃん, ゆるゆり♪♪, ねこ')\n",
      "('121188753', '東方Project, パチュリー, 女の子')\n",
      "('121188754', 'heroforge, scifi, future, robot, assassin, knife, android, percia, gun, heroforge')\n",
      "('121188755', '練習, 模写')\n",
      "('121188756', '漫画, 光る君へ, 源倫子, 藤原道長, まひろ, 藤原賢子')\n",
      "('121188758', '初音ミク, VOCALOID')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('web_info.db')\n",
    "cur = con.cursor()\n",
    "\n",
    "for row in cur.execute(\"SELECT work_ID,tags FROM web_info ORDER BY work_ID\"):\n",
    "    print(row)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37104cd1-a3e8-47d3-a466-2b4b61a2c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片已成功保存为 downloaded_image.png\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import requests\n",
    "\n",
    "# 图片的 URL\n",
    "url = 'https://i.pximg.net/img-master/img/2024/08/05/22/47/33/121215791_p0_master1200.jpg'\n",
    "\n",
    "# 图片保存的本地文件名\n",
    "filename = 'downloaded_image.png'\n",
    "\n",
    "# 请求头，模拟完整的浏览器请求\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36',\n",
    "    'Referer': 'https://www.pixiv.net/',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# 发起 GET 请求以下载图片\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 检查请求是否成功\n",
    "if response.status_code == 200:\n",
    "    # 将图片数据写入本地文件\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"图片已成功保存为 {filename}\")\n",
    "else:\n",
    "    print(f\"图片下载失败，状态码：{response.status_code}\")\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662c282-045f-46fe-9c92-afe79094a532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
